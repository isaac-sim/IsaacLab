

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Teleoperation and Imitation Learning with Isaac Lab Mimic &#8212; Isaac Lab Documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/twemoji.css" />
    <link rel="stylesheet" type="text/css" href="/opt/hostedtoolcache/Python/3.11.13/x64/lib/python3.11/site-packages/sphinxcontrib/icon/node_modules/@fortawesome/fontawesome-free/css/all.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.4cbf315f70debaebd550c87a6162cf0f.min.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="https://unpkg.com/twemoji@latest/dist/twemoji.min.js"></script>
    <script src="../../../_static/twemoji.js"></script>
    <script src="/opt/hostedtoolcache/Python/3.11.13/x64/lib/python3.11/site-packages/sphinxcontrib/icon/node_modules/@fortawesome/fontawesome-free/js/all.min.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'source/overview/imitation-learning/teleop_imitation';</script>
    <link rel="icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Augmented Imitation Learning" href="augmented_imitation.html" />
    <link rel="prev" title="Imitation Learning" href="index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="2.3.0" />
    <meta name="docbuild:last-update" content="Oct 15, 2025"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/NVIDIA-logo-white.png" class="logo__image only-light" alt=""/>
    <img src="../../../_static/NVIDIA-logo-black.png" class="logo__image only-dark pst-js-only" alt=""/>
  
  
    <p class="title logo__title">Isaac Lab Documentation</p>
  
</a></div>
        <div class="sidebar-primary-item">
<nav class="bd-links bd-docs-nav">
    <div class="bd-toc-item navbar-nav">
      <ul class="nav bd-sidenav">
        <li class="toctree-l1 has-children" style="display: flex; justify-content: center; align-items: center; flex-direction: column;">
          <div  style ="text-align:center;">
            <label for="version-select" style="font-weight: bold; display: block;">Version</label>
          </div>
          <select id="version-select" class="version-dropdown" style="margin: 0 auto; display: block;" onchange="location = this.value;">
            <option value="teleop_imitation.html" selected>release/2.3.0</option>
            <option value="../../../../../main/source/overview/imitation-learning/teleop_imitation.html" >main</option>
            <option value="../../../../2.1.0/index.html" >release/2.1.0</option>
            <option value="../../../../2.2.0/index.html" >release/2.2.0</option>
            <option value="../../../../../v2.2.1/source/overview/imitation-learning/teleop_imitation.html" >v2.2.1</option>
            <option value="../../../../../v2.2.0/index.html" >v2.2.0</option>
            <option value="../../../../../v2.1.1/index.html" >v2.1.1</option>
            <option value="../../../../../v2.1.0/index.html" >v2.1.0</option>
            <option value="../../../../../v2.0.2/index.html" >v2.0.2</option>
            <option value="../../../../../v2.0.1/index.html" >v2.0.1</option>
            <option value="../../../../../v2.0.0/index.html" >v2.0.0</option>
            <option value="../../../../../v1.4.1/index.html" >v1.4.1</option>
            <option value="../../../../../v1.4.0/index.html" >v1.4.0</option>
            <option value="../../../../../v1.3.0/index.html" >v1.3.0</option>
            <option value="../../../../../v1.2.0/index.html" >v1.2.0</option>
            <option value="../../../../../v1.1.0/index.html" >v1.1.0</option>
            <option value="../../../../../v1.0.0/index.html" >v1.0.0</option>
          </select>
        </li>
      </ul>
    </div>
</nav>
</div>
        <div class="sidebar-primary-item"><ul class="navbar-icon-links"
    aria-label="Quick Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/isaac-sim/IsaacLab" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://developer.nvidia.com/isaac-sim" title="Isaac Sim" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><img src="https://img.shields.io/badge/IsaacSim-5.1.0-silver.svg" class="icon-link-image" alt="Isaac Sim"/></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://img.shields.io/github/stars/isaac-sim/IsaacLab?color=fedcba" title="Stars" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><img src="https://img.shields.io/github/stars/isaac-sim/IsaacLab?color=fedcba" class="icon-link-image" alt="Stars"/></a>
        </li>
</ul></div>
        <div class="sidebar-primary-item">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Isaac Lab</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../setup/ecosystem.html">Isaac Lab Ecosystem</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../setup/installation/index.html">Local Installation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../setup/installation/pip_installation.html">Installation using Isaac Sim Pip Package</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/installation/binaries_installation.html">Installation using Isaac Sim Pre-built Binaries</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/installation/source_installation.html">Installation using Isaac Sim Source Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/installation/isaaclab_pip_installation.html">Installation using Isaac Lab Pip Packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/installation/asset_caching.html">Asset Caching</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../deployment/index.html">Container Deployment</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../deployment/docker.html">Docker Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../deployment/run_docker_example.html">Running an example with Docker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../deployment/cluster.html">Cluster Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../deployment/cloudxr_teleoperation_cluster.html">Deploying CloudXR Teleoperation on Kubernetes</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../setup/installation/cloud_installation.html">Cloud Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/reference_architecture/index.html">Reference Architecture</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../setup/quickstart.html">Quickstart Guide</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../own-project/index.html">Build your Own Project or Task</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../own-project/template.html">Create new project or task</a></li>
<li class="toctree-l2"><a class="reference internal" href="../own-project/project_structure.html">Project Structure</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../setup/walkthrough/index.html">Walkthrough</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../setup/walkthrough/concepts_env_design.html">Environment Design Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/walkthrough/api_env_design.html">Classes and Configs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/walkthrough/technical_env_design.html">Environment Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/walkthrough/training_jetbot_gt.html">Training the Jetbot: Ground Truth</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/walkthrough/training_jetbot_reward_exploration.html">Exploring the RL problem</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/index.html">Tutorials</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/00_sim/create_empty.html">Creating an empty scene</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/00_sim/spawn_prims.html">Spawning prims into the scene</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/00_sim/launch_app.html">Deep-dive into AppLauncher</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/01_assets/add_new_robot.html">Adding a New Robot to Isaac Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/01_assets/run_rigid_object.html">Interacting with a rigid object</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/01_assets/run_articulation.html">Interacting with an articulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/01_assets/run_deformable_object.html">Interacting with a deformable object</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/01_assets/run_surface_gripper.html">Interacting with a surface gripper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/02_scene/create_scene.html">Using the Interactive Scene</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/create_manager_base_env.html">Creating a Manager-Based Base Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/create_manager_rl_env.html">Creating a Manager-Based RL Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/create_direct_rl_env.html">Creating a Direct Workflow RL Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/register_rl_env_gym.html">Registering an Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/run_rl_training.html">Training with an RL Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/configuring_rl_training.html">Configuring an RL Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/modify_direct_rl_env.html">Modifying an existing Direct RL Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/policy_inference_in_usd.html">Policy Inference in USD Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/04_sensors/add_sensors_on_robot.html">Adding sensors on a robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/05_controllers/run_diff_ik.html">Using a task-space controller</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/05_controllers/run_osc.html">Using an operational space controller</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../how-to/index.html">How-to Guides</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/import_new_asset.html">Importing a New Asset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/write_articulation_cfg.html">Writing an Asset Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/make_fixed_prim.html">Making a physics prim fixed in the simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/multi_asset_spawning.html">Spawning Multiple Assets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/save_camera_output.html">Saving rendered images and 3D re-projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/estimate_how_many_cameras_can_run.html">Find How Many/What Cameras You Should Train With</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/configure_rendering.html">Configuring Rendering Settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/draw_markers.html">Creating Visualization Markers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/wrap_rl_env.html">Wrapping environments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/add_own_library.html">Adding your own learning library</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/record_animation.html">Recording Animations of Simulations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/record_video.html">Recording video clips during training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/curriculums.html">Curriculum Utilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/master_omniverse.html">Mastering Omniverse for Robotics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/cloudxr_teleoperation.html">Setting up CloudXR Teleoperation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/simulation_performance.html">Simulation Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/optimize_stage_creation.html">Optimize Stage Creation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../developer-guide/index.html">Developer’s Guide</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../developer-guide/vs_code.html">Setting up Visual Studio Code</a></li>

<li class="toctree-l2"><a class="reference internal" href="../developer-guide/repo_structure.html">Repository organization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developer-guide/development.html">Extension Development</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../core-concepts/index.html">Core Concepts</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../core-concepts/task_workflows.html">Task Design Workflows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../core-concepts/actuators.html">Actuators</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../core-concepts/sensors/index.html">Sensors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../core-concepts/sensors/camera.html">Camera</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core-concepts/sensors/contact_sensor.html">Contact Sensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core-concepts/sensors/frame_transformer.html">Frame Transformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core-concepts/sensors/imu.html">Inertial Measurement Unit (IMU)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core-concepts/sensors/ray_caster.html">Ray Caster</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../core-concepts/motion_generators.html">Motion Generators</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../environments.html">Available Environments</a></li>

<li class="toctree-l1 has-children"><a class="reference internal" href="../reinforcement-learning/index.html">Reinforcement Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../reinforcement-learning/rl_existing_scripts.html">Reinforcement Learning Scripts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reinforcement-learning/rl_frameworks.html">Reinforcement Learning Library Comparison</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reinforcement-learning/performance_benchmarks.html">Performance Benchmarks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reinforcement-learning/training_guide.html">Debugging and Training Guide</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Imitation Learning</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Teleoperation and Imitation Learning with Isaac Lab Mimic</a></li>
<li class="toctree-l2"><a class="reference internal" href="augmented_imitation.html">Augmented Imitation Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="skillgen.html">SkillGen for Automated Demonstration Generation</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../showroom.html">Showroom Demos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../simple_agents.html">Simple Agents</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Features</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../features/hydra.html">Hydra Configuration System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../features/multi_gpu.html">Multi-GPU and Multi-Node Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../features/population_based_training.html">Population Based Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../core-concepts/sensors/camera.html">Tiled Rendering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../features/ray.html">Ray Job Dispatch and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../features/reproducibility.html">Reproducibility and Determinism</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Experimental Features</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../experimental-features/bleeding-edge.html">Welcome to the bleeding edge!</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../experimental-features/newton-physics-integration/index.html">Newton Physics Integration</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../experimental-features/newton-physics-integration/installation.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../experimental-features/newton-physics-integration/training-environments.html">Training Environments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../experimental-features/newton-physics-integration/newton-visualizer.html">Newton Visualizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../experimental-features/newton-physics-integration/limitations-and-known-bugs.html">Limitations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../experimental-features/newton-physics-integration/solver-transitioning.html">Solver Transitioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../experimental-features/newton-physics-integration/sim-to-sim.html">Sim-to-Sim Policy Transfer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../experimental-features/newton-physics-integration/sim-to-real.html">Sim-to-Real Policy Transfer</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../setup/installation/cloud_installation.html">Cloud Deployment</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../policy_deployment/index.html">Sim2Real Deployment of Policies Trained in Isaac Lab</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../policy_deployment/00_hover/hover_policy.html">Training &amp; Deploying HOVER Policy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../policy_deployment/01_io_descriptors/io_descriptors_101.html">IO Descriptors 101</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Migration Guides</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../migration/migrating_from_isaacgymenvs.html">From IsaacGymEnvs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration/migrating_from_omniisaacgymenvs.html">From OmniIsaacGymEnvs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration/migrating_from_orbit.html">From Orbit</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Source API</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../api/index.html">API Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.app.html">isaaclab.app</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.actuators.html">isaaclab.actuators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.assets.html">isaaclab.assets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.controllers.html">isaaclab.controllers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.devices.html">isaaclab.devices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.envs.html">isaaclab.envs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.managers.html">isaaclab.managers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.markers.html">isaaclab.markers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.scene.html">isaaclab.scene</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.sensors.html">isaaclab.sensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.sim.html">isaaclab.sim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.terrains.html">isaaclab.terrains</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.utils.html">isaaclab.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.envs.mdp.html">isaaclab.envs.mdp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.envs.ui.html">isaaclab.envs.ui</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.sensors.patterns.html">isaaclab.sensors.patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.sim.converters.html">isaaclab.sim.converters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.sim.schemas.html">isaaclab.sim.schemas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.sim.spawners.html">isaaclab.sim.spawners</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_rl/isaaclab_rl.html">isaaclab_rl</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_mimic/isaaclab_mimic.datagen.html">isaaclab_mimic.datagen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_mimic/isaaclab_mimic.envs.html">isaaclab_mimic.envs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_tasks/isaaclab_tasks.utils.html">isaaclab_tasks.utils</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../refs/additional_resources.html">Additional Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/contributing.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/troubleshooting.html">Tricks and Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/migration.html">Migration Guide (Isaac Sim)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/issues.html">Known Issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/changelog.html">Extensions Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/bibliography.html">Bibliography</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project Links</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://github.com/isaac-sim/IsaacLab">GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.isaacsim.omniverse.nvidia.com/latest/index.html">NVIDIA Isaac Sim</a></li>
<li class="toctree-l1"><a class="reference external" href="https://nvidia-omniverse.github.io/PhysX/physx/5.4.1/index.html">NVIDIA PhysX</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/isaac-sim/IsaacLab" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/isaac-sim/IsaacLab/edit/main/docs/source/overview/imitation-learning/teleop_imitation.rst" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/isaac-sim/IsaacLab/issues/new?title=Issue%20on%20page%20%2Fsource/overview/imitation-learning/teleop_imitation.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/source/overview/imitation-learning/teleop_imitation.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Teleoperation and Imitation Learning with Isaac Lab Mimic</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teleoperation">Teleoperation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imitation-learning-with-isaac-lab-mimic">Imitation Learning with Isaac Lab Mimic</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#collecting-demonstrations">Collecting demonstrations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-recorded-demonstrations">Pre-recorded demonstrations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-additional-demonstrations-with-isaac-lab-mimic">Generating additional demonstrations with Isaac Lab Mimic</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robomimic-setup">Robomimic setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-an-agent">Training an agent</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-results">Visualizing results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-1-data-generation-and-policy-training-for-a-humanoid-robot">Demo 1: Data Generation and Policy Training for a Humanoid Robot</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-collect-and-annotate-demonstrations">Optional: Collect and annotate demonstrations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#collect-human-demonstrations">Collect human demonstrations</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#annotate-the-demonstrations">Annotate the demonstrations</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-dataset">Generate the dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-policy">Train a policy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-results">Visualize the results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-2-data-generation-and-policy-training-for-humanoid-robot-locomanipulation-with-unitree-g1">Demo 2: Data Generation and Policy Training for Humanoid Robot Locomanipulation with Unitree G1</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-manipulation-dataset">Generate the manipulation dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-manipulation-only-policy">Train a manipulation-only policy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Visualize the results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-dataset-with-manipulation-and-point-to-point-navigation">Generate the dataset with manipulation and point-to-point navigation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-3-visuomotor-policy-for-a-humanoid-robot">Demo 3: Visuomotor Policy for a Humanoid Robot</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#download-the-dataset">Download the Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Train a policy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-results-demo-2">Visualize the results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#common-pitfalls-when-generating-data">Common Pitfalls when Generating Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-your-own-isaac-lab-mimic-compatible-environments">Creating Your Own Isaac Lab Mimic Compatible Environments</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-it-works">How it works</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration-and-subtask-definition">Configuration and subtask definition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#subtask-annotation">Subtask annotation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#helpers-for-demonstration-generation">Helpers for demonstration generation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#registering-the-environment">Registering the environment</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tips-for-successful-data-generation-with-isaac-lab-mimic">Tips for Successful Data Generation with Isaac Lab Mimic</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#splitting-subtasks">Splitting subtasks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#selecting-number-of-interpolation-steps">Selecting number of interpolation steps</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="teleoperation-and-imitation-learning-with-isaac-lab-mimic">
<span id="teleoperation-imitation-learning"></span><h1>Teleoperation and Imitation Learning with Isaac Lab Mimic<a class="headerlink" href="#teleoperation-and-imitation-learning-with-isaac-lab-mimic" title="Permalink to this heading">#</a></h1>
<section id="teleoperation">
<h2>Teleoperation<a class="headerlink" href="#teleoperation" title="Permalink to this heading">#</a></h2>
<p>We provide interfaces for providing commands in SE(2) and SE(3) space
for robot control. In case of SE(2) teleoperation, the returned command
is the linear x-y velocity and yaw rate, while in SE(3), the returned
command is a 6-D vector representing the change in pose.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Presently, Isaac Lab Mimic is only supported in Linux.</p>
</div>
<p>To play inverse kinematics (IK) control with a keyboard device:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/environments/teleoperation/teleop_se3_agent.py<span class="w"> </span>--task<span class="w"> </span>Isaac-Stack-Cube-Franka-IK-Rel-v0<span class="w"> </span>--num_envs<span class="w"> </span><span class="m">1</span><span class="w"> </span>--teleop_device<span class="w"> </span>keyboard
</pre></div>
</div>
<p>For smoother operation and off-axis operation, we recommend using a SpaceMouse as the input device. Providing smoother demonstrations will make it easier for the policy to clone the behavior. To use a SpaceMouse, simply change the teleop device accordingly:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/environments/teleoperation/teleop_se3_agent.py<span class="w"> </span>--task<span class="w"> </span>Isaac-Stack-Cube-Franka-IK-Rel-v0<span class="w"> </span>--num_envs<span class="w"> </span><span class="m">1</span><span class="w"> </span>--teleop_device<span class="w"> </span>spacemouse
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the SpaceMouse is not detected, you may need to grant additional user permissions by running <code class="docutils literal notranslate"><span class="pre">sudo</span> <span class="pre">chmod</span> <span class="pre">666</span> <span class="pre">/dev/hidraw&lt;#&gt;</span></code> where <code class="docutils literal notranslate"><span class="pre">&lt;#&gt;</span></code> corresponds to the device index
of the connected SpaceMouse.</p>
<p>To determine the device index, list all <code class="docutils literal notranslate"><span class="pre">hidraw</span></code> devices by running <code class="docutils literal notranslate"><span class="pre">ls</span> <span class="pre">-l</span> <span class="pre">/dev/hidraw*</span></code>.
Identify the device corresponding to the SpaceMouse by running <code class="docutils literal notranslate"><span class="pre">cat</span> <span class="pre">/sys/class/hidraw/hidraw&lt;#&gt;/device/uevent</span></code> on each of the devices listed
from the prior step.</p>
<p>We recommend using local deployment of Isaac Lab to use the SpaceMouse. If using container deployment (<a class="reference internal" href="../../deployment/docker.html#deployment-docker"><span class="std std-ref">Docker Guide</span></a>), you must manually mount the SpaceMouse to the <code class="docutils literal notranslate"><span class="pre">isaac-lab-base</span></code> container by
adding a <code class="docutils literal notranslate"><span class="pre">devices</span></code> attribute with the path to the device in your <code class="docutils literal notranslate"><span class="pre">docker-compose.yaml</span></code> file:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">devices</span><span class="p">:</span>
<span class="w">   </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/dev/hidraw&lt;#&gt;:/dev/hidraw&lt;#&gt;</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">&lt;#&gt;</span></code> is the device index of the connected SpaceMouse.</p>
<p>If you are using the IsaacLab + CloudXR container deployment (<a class="reference internal" href="../../how-to/cloudxr_teleoperation.html#cloudxr-teleoperation"><span class="std std-ref">Setting up CloudXR Teleoperation</span></a>), you can add the <code class="docutils literal notranslate"><span class="pre">devices</span></code> attribute under the <code class="docutils literal notranslate"><span class="pre">services</span> <span class="pre">-&gt;</span> <span class="pre">isaac-lab-base</span></code> section of the
<code class="docutils literal notranslate"><span class="pre">docker/docker-compose.cloudxr-runtime.patch.yaml</span></code> file.</p>
<p>Isaac Lab is only compatible with the SpaceMouse Wireless and SpaceMouse Compact models from 3Dconnexion.</p>
</div>
<p>For tasks that benefit from the use of an extended reality (XR) device with hand tracking, Isaac Lab supports using NVIDIA CloudXR to immersively stream the scene to compatible XR devices for teleoperation. Note that when using hand tracking we recommend using the absolute variant of the task (<code class="docutils literal notranslate"><span class="pre">Isaac-Stack-Cube-Franka-IK-Abs-v0</span></code>), which requires the <code class="docutils literal notranslate"><span class="pre">handtracking</span></code> device:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/environments/teleoperation/teleop_se3_agent.py<span class="w"> </span>--task<span class="w"> </span>Isaac-Stack-Cube-Franka-IK-Abs-v0<span class="w"> </span>--teleop_device<span class="w"> </span>handtracking<span class="w"> </span>--device<span class="w"> </span>cpu
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>See <a class="reference internal" href="../../how-to/cloudxr_teleoperation.html#cloudxr-teleoperation"><span class="std std-ref">Setting up CloudXR Teleoperation</span></a> to learn how to use CloudXR and experience teleoperation with Isaac Lab.</p>
</div>
<p>The script prints the teleoperation events configured. For keyboard,
these are as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Keyboard Controller for SE(3): Se3Keyboard
   Reset all commands: R
   Toggle gripper (open/close): K
   Move arm along x-axis: W/S
   Move arm along y-axis: A/D
   Move arm along z-axis: Q/E
   Rotate arm along x-axis: Z/X
   Rotate arm along y-axis: T/G
   Rotate arm along z-axis: C/V
</pre></div>
</div>
<p>For SpaceMouse, these are as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>SpaceMouse Controller for SE(3): Se3SpaceMouse
   Reset all commands: Right click
   Toggle gripper (open/close): Click the left button on the SpaceMouse
   Move arm along x/y-axis: Tilt the SpaceMouse
   Move arm along z-axis: Push or pull the SpaceMouse
   Rotate arm: Twist the SpaceMouse
</pre></div>
</div>
<p>The next section describes how teleoperation devices can be used for data collection for imitation learning.</p>
</section>
<section id="imitation-learning-with-isaac-lab-mimic">
<h2>Imitation Learning with Isaac Lab Mimic<a class="headerlink" href="#imitation-learning-with-isaac-lab-mimic" title="Permalink to this heading">#</a></h2>
<p>Using the teleoperation devices, it is also possible to collect data for
learning from demonstrations (LfD). For this, we provide scripts to collect data into the open HDF5 format.</p>
<section id="collecting-demonstrations">
<h3>Collecting demonstrations<a class="headerlink" href="#collecting-demonstrations" title="Permalink to this heading">#</a></h3>
<p>To collect demonstrations with teleoperation for the environment <code class="docutils literal notranslate"><span class="pre">Isaac-Stack-Cube-Franka-IK-Rel-v0</span></code>, use the following commands:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># step a: create folder for datasets</span>
mkdir<span class="w"> </span>-p<span class="w"> </span>datasets
<span class="c1"># step b: collect data with a selected teleoperation device. Replace &lt;teleop_device&gt; with your preferred input device.</span>
<span class="c1"># Available options: spacemouse, keyboard, handtracking</span>
./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/tools/record_demos.py<span class="w"> </span>--task<span class="w"> </span>Isaac-Stack-Cube-Franka-IK-Rel-v0<span class="w"> </span>--device<span class="w"> </span>cpu<span class="w"> </span>--teleop_device<span class="w"> </span>&lt;teleop_device&gt;<span class="w"> </span>--dataset_file<span class="w"> </span>./datasets/dataset.hdf5<span class="w"> </span>--num_demos<span class="w"> </span><span class="m">10</span>
<span class="c1"># step a: replay the collected dataset</span>
./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/tools/replay_demos.py<span class="w"> </span>--task<span class="w"> </span>Isaac-Stack-Cube-Franka-IK-Rel-v0<span class="w"> </span>--device<span class="w"> </span>cpu<span class="w"> </span>--dataset_file<span class="w"> </span>./datasets/dataset.hdf5
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The order of the stacked cubes should be blue (bottom), red (middle), green (top).</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>When using an XR device, we suggest collecting demonstrations with the <code class="docutils literal notranslate"><span class="pre">Isaac-Stack-Cube-Frank-IK-Abs-v0</span></code> version of the task and <code class="docutils literal notranslate"><span class="pre">--teleop_device</span> <span class="pre">handtracking</span></code>, which controls the end effector using the absolute position of the hand.</p>
</div>
<p>About 10 successful demonstrations are required in order for the following steps to succeed.</p>
<p>Here are some tips to perform demonstrations that lead to successful policy training:</p>
<ul class="simple">
<li><p>Keep demonstrations short. Shorter demonstrations mean fewer decisions for the policy, making training easier.</p></li>
<li><p>Take a direct path. Do not follow along arbitrary axis, but move straight toward the goal.</p></li>
<li><p>Do not pause. Perform smooth, continuous motions instead. It is not obvious for a policy why and when to pause, hence continuous motions are easier to learn.</p></li>
</ul>
<p>If, while performing a demonstration, a mistake is made, or the current demonstration should not be recorded for some other reason, press the <code class="docutils literal notranslate"><span class="pre">R</span></code> key to discard the current demonstration, and reset to a new starting position.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Non-determinism may be observed during replay as physics in IsaacLab are not determimnistically reproducible when using <code class="docutils literal notranslate"><span class="pre">env.reset</span></code>.</p>
</div>
</section>
<section id="pre-recorded-demonstrations">
<h3>Pre-recorded demonstrations<a class="headerlink" href="#pre-recorded-demonstrations" title="Permalink to this heading">#</a></h3>
<p>We provide a pre-recorded <code class="docutils literal notranslate"><span class="pre">dataset.hdf5</span></code> containing 10 human demonstrations for <code class="docutils literal notranslate"><span class="pre">Isaac-Stack-Cube-Franka-IK-Rel-v0</span></code>
here: <a class="reference external" href="https://omniverse-content-production.s3-us-west-2.amazonaws.com/Assets/Isaac/5.1/Isaac/IsaacLab/Mimic/franka_stack_datasets/dataset.hdf5">[Franka Dataset]</a>.
This dataset may be downloaded and used in the remaining tutorial steps if you do not wish to collect your own demonstrations.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Use of the pre-recorded dataset is optional.</p>
</div>
</section>
<section id="generating-additional-demonstrations-with-isaac-lab-mimic">
<h3>Generating additional demonstrations with Isaac Lab Mimic<a class="headerlink" href="#generating-additional-demonstrations-with-isaac-lab-mimic" title="Permalink to this heading">#</a></h3>
<p>Additional demonstrations can be generated using Isaac Lab Mimic.</p>
<p>Isaac Lab Mimic is a feature in Isaac Lab that allows generation of additional demonstrations automatically, allowing a policy to learn successfully even from just a handful of manual demonstrations.</p>
<p>In the following example, we will show how to use Isaac Lab Mimic to generate additional demonstrations that can be used to train either a state-based policy
(using the <code class="docutils literal notranslate"><span class="pre">Isaac-Stack-Cube-Franka-IK-Rel-Mimic-v0</span></code> environment) or visuomotor policy (using the <code class="docutils literal notranslate"><span class="pre">Isaac-Stack-Cube-Franka-IK-Rel-Visuomotor-Mimic-v0</span></code> environment).</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>All commands in the following sections must keep a consistent policy type. For example, if choosing to use a state-based policy, then all commands used should be from the “State-based policy” tab.</p>
</div>
<p>In order to use Isaac Lab Mimic with the recorded dataset, first annotate the subtasks in the recording:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" data-sync-group="policy_type" data-sync-id="state" for="sd-tab-item-0">
State-based policy</label><div class="sd-tab-content docutils">
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/annotate_demos.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span>--task<span class="w"> </span>Isaac-Stack-Cube-Franka-IK-Rel-Mimic-v0<span class="w"> </span>--auto<span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/dataset.hdf5<span class="w"> </span>--output_file<span class="w"> </span>./datasets/annotated_dataset.hdf5
</pre></div>
</div>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" data-sync-group="policy_type" data-sync-id="visuomotor" for="sd-tab-item-1">
Visuomotor policy</label><div class="sd-tab-content docutils">
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/annotate_demos.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span>--enable_cameras<span class="w"> </span>--task<span class="w"> </span>Isaac-Stack-Cube-Franka-IK-Rel-Visuomotor-Mimic-v0<span class="w"> </span>--auto<span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/dataset.hdf5<span class="w"> </span>--output_file<span class="w"> </span>./datasets/annotated_dataset.hdf5
</pre></div>
</div>
</div>
</div>
<p>Then, use Isaac Lab Mimic to generate some additional demonstrations:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-2" name="sd-tab-set-1" type="radio">
<label class="sd-tab-label" data-sync-group="policy_type" data-sync-id="state" for="sd-tab-item-2">
State-based policy</label><div class="sd-tab-content docutils">
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/generate_dataset.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span>--num_envs<span class="w"> </span><span class="m">10</span><span class="w"> </span>--generation_num_trials<span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/annotated_dataset.hdf5<span class="w"> </span>--output_file<span class="w"> </span>./datasets/generated_dataset_small.hdf5
</pre></div>
</div>
</div>
<input id="sd-tab-item-3" name="sd-tab-set-1" type="radio">
<label class="sd-tab-label" data-sync-group="policy_type" data-sync-id="visuomotor" for="sd-tab-item-3">
Visuomotor policy</label><div class="sd-tab-content docutils">
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/generate_dataset.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span>--enable_cameras<span class="w"> </span>--num_envs<span class="w"> </span><span class="m">10</span><span class="w"> </span>--generation_num_trials<span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/annotated_dataset.hdf5<span class="w"> </span>--output_file<span class="w"> </span>./datasets/generated_dataset_small.hdf5
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The output_file of the <code class="docutils literal notranslate"><span class="pre">annotate_demos.py</span></code> script is the input_file to the <code class="docutils literal notranslate"><span class="pre">generate_dataset.py</span></code> script</p>
</div>
<p>Inspect the output of generated data (filename: <code class="docutils literal notranslate"><span class="pre">generated_dataset_small.hdf5</span></code>), and if satisfactory, generate the full dataset:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-4" name="sd-tab-set-2" type="radio">
<label class="sd-tab-label" data-sync-group="policy_type" data-sync-id="state" for="sd-tab-item-4">
State-based policy</label><div class="sd-tab-content docutils">
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/generate_dataset.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span>--headless<span class="w"> </span>--num_envs<span class="w"> </span><span class="m">10</span><span class="w"> </span>--generation_num_trials<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/annotated_dataset.hdf5<span class="w"> </span>--output_file<span class="w"> </span>./datasets/generated_dataset.hdf5
</pre></div>
</div>
</div>
<input id="sd-tab-item-5" name="sd-tab-set-2" type="radio">
<label class="sd-tab-label" data-sync-group="policy_type" data-sync-id="visuomotor" for="sd-tab-item-5">
Visuomotor policy</label><div class="sd-tab-content docutils">
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/generate_dataset.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span>--enable_cameras<span class="w"> </span>--headless<span class="w"> </span>--num_envs<span class="w"> </span><span class="m">10</span><span class="w"> </span>--generation_num_trials<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/annotated_dataset.hdf5<span class="w"> </span>--output_file<span class="w"> </span>./datasets/generated_dataset.hdf5
</pre></div>
</div>
</div>
</div>
<p>The number of demonstrations can be increased or decreased, 1000 demonstrations have been shown to provide good training results for this task.</p>
<p>Additionally, the number of environments in the <code class="docutils literal notranslate"><span class="pre">--num_envs</span></code> parameter can be adjusted to speed up data generation.
The suggested number of 10 can be executed on a moderate laptop GPU.
On a more powerful desktop machine, use a larger number of environments for a significant speedup of this step.</p>
</section>
<section id="robomimic-setup">
<h3>Robomimic setup<a class="headerlink" href="#robomimic-setup" title="Permalink to this heading">#</a></h3>
<p>As an example, we will train a BC agent implemented in <a class="reference external" href="https://robomimic.github.io/">Robomimic</a> to train a policy. Any other framework or training method could be used.</p>
<p>To install the robomimic framework, use the following commands:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># install the dependencies</span>
sudo<span class="w"> </span>apt<span class="w"> </span>install<span class="w"> </span>cmake<span class="w"> </span>build-essential
<span class="c1"># install python module (for robomimic)</span>
./isaaclab.sh<span class="w"> </span>-i<span class="w"> </span>robomimic
</pre></div>
</div>
</section>
<section id="training-an-agent">
<h3>Training an agent<a class="headerlink" href="#training-an-agent" title="Permalink to this heading">#</a></h3>
<p>Using the Mimic generated data we can now train a state-based BC agent for <code class="docutils literal notranslate"><span class="pre">Isaac-Stack-Cube-Franka-IK-Rel-v0</span></code>, or a visuomotor BC agent for <code class="docutils literal notranslate"><span class="pre">Isaac-Stack-Cube-Franka-IK-Rel-Visuomotor-v0</span></code>:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-6" name="sd-tab-set-3" type="radio">
<label class="sd-tab-label" data-sync-group="policy_type" data-sync-id="state" for="sd-tab-item-6">
State-based policy</label><div class="sd-tab-content docutils">
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/train.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-Stack-Cube-Franka-IK-Rel-v0<span class="w"> </span>--algo<span class="w"> </span>bc<span class="w"> </span><span class="se">\</span>
--dataset<span class="w"> </span>./datasets/generated_dataset.hdf5
</pre></div>
</div>
</div>
<input id="sd-tab-item-7" name="sd-tab-set-3" type="radio">
<label class="sd-tab-label" data-sync-group="policy_type" data-sync-id="visuomotor" for="sd-tab-item-7">
Visuomotor policy</label><div class="sd-tab-content docutils">
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/train.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-Stack-Cube-Franka-IK-Rel-Visuomotor-v0<span class="w"> </span>--algo<span class="w"> </span>bc<span class="w"> </span><span class="se">\</span>
--dataset<span class="w"> </span>./datasets/generated_dataset.hdf5
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By default the trained models and logs will be saved to <code class="docutils literal notranslate"><span class="pre">IssacLab/logs/robomimic</span></code>.</p>
</div>
</section>
<section id="visualizing-results">
<h3>Visualizing results<a class="headerlink" href="#visualizing-results" title="Permalink to this heading">#</a></h3>
<p>By inferencing using the generated model, we can visualize the results of the policy:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-8" name="sd-tab-set-4" type="radio">
<label class="sd-tab-label" data-sync-group="policy_type" data-sync-id="state" for="sd-tab-item-8">
State-based policy</label><div class="sd-tab-content docutils">
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/play.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span>--task<span class="w"> </span>Isaac-Stack-Cube-Franka-IK-Rel-v0<span class="w"> </span>--num_rollouts<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
--checkpoint<span class="w"> </span>/PATH/TO/desired_model_checkpoint.pth
</pre></div>
</div>
</div>
<input id="sd-tab-item-9" name="sd-tab-set-4" type="radio">
<label class="sd-tab-label" data-sync-group="policy_type" data-sync-id="visuomotor" for="sd-tab-item-9">
Visuomotor policy</label><div class="sd-tab-content docutils">
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/play.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span>--enable_cameras<span class="w"> </span>--task<span class="w"> </span>Isaac-Stack-Cube-Franka-IK-Rel-Visuomotor-v0<span class="w"> </span>--num_rollouts<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
--checkpoint<span class="w"> </span>/PATH/TO/desired_model_checkpoint.pth
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="demo-1-data-generation-and-policy-training-for-a-humanoid-robot">
<h2>Demo 1: Data Generation and Policy Training for a Humanoid Robot<a class="headerlink" href="#demo-1-data-generation-and-policy-training-for-a-humanoid-robot" title="Permalink to this heading">#</a></h2>
<figure class="align-center">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place.gif"><img alt="GR-1 humanoid robot performing a pick and place task" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place.gif" style="width: 100%;" /></a>
</figure>
<p>Isaac Lab Mimic supports data generation for robots with multiple end effectors. In the following demonstration, we will show how to generate data
to train a Fourier GR-1 humanoid robot to perform a pick and place task.</p>
<section id="optional-collect-and-annotate-demonstrations">
<h3>Optional: Collect and annotate demonstrations<a class="headerlink" href="#optional-collect-and-annotate-demonstrations" title="Permalink to this heading">#</a></h3>
<section id="collect-human-demonstrations">
<h4>Collect human demonstrations<a class="headerlink" href="#collect-human-demonstrations" title="Permalink to this heading">#</a></h4>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Data collection for the GR-1 humanoid robot environment requires use of an Apple Vision Pro headset. If you do not have access to
an Apple Vision Pro, you may skip this step and continue on to the next step: <a class="reference internal" href="#generate-the-dataset">Generate the dataset</a>.
A pre-recorded annotated dataset is provided in the next step.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The GR1 scene utilizes the wrist poses from the Apple Vision Pro (AVP) as setpoints for a differential IK controller (Pink-IK).
The differential IK controller requires the user’s wrist pose to be close to the robot’s initial or current pose for optimal performance.
Rapid movements of the user’s wrist may cause it to deviate significantly from the goal state, which could prevent the IK controller from finding the optimal solution.
This may result in a mismatch between the user’s wrist and the robot’s wrist.
You can increase the gain of all the <a class="reference external" href="https://github.com/isaac-sim/IsaacLab/blob/main/source/isaaclab_tasks/isaaclab_tasks/manager_based/manipulation/pick_place/pickplace_gr1t2_env_cfg.py">Pink-IK controller’s FrameTasks</a> to track the AVP wrist poses with lower latency.
However, this may lead to more jerky motion.
Separately, the finger joints of the robot are retargeted to the user’s finger joints using the <a class="reference external" href="https://github.com/dexsuite/dex-retargeting">dex-retargeting</a> library.</p>
</div>
<p>Set up the CloudXR Runtime and Apple Vision Pro for teleoperation by following the steps in <a class="reference internal" href="../../how-to/cloudxr_teleoperation.html#cloudxr-teleoperation"><span class="std std-ref">Setting up CloudXR Teleoperation</span></a>.
CPU simulation is used in the following steps for better XR performance when running a single environment.</p>
<p>Collect a set of human demonstrations.
A success demo requires the object to be placed in the bin and for the robot’s right arm to be retracted to the starting position.</p>
<p>The Isaac Lab Mimic Env GR-1 humanoid robot is set up such that the left hand has a single subtask, while the right hand has two subtasks.
The first subtask involves the right hand remaining idle while the left hand picks up and moves the object to the position where the right hand will grasp it.
This setup allows Isaac Lab Mimic to interpolate the right hand’s trajectory accurately by using the object’s pose, especially when poses are randomized during data generation.
Therefore, avoid moving the right hand while the left hand picks up the object and brings it to a stable position.</p>
<p><a class="reference internal" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place_good_demo.gif"><img alt="GR-1 humanoid robot performing a good pick and place demonstration" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place_good_demo.gif" style="width: 49%;" /></a> <a class="reference internal" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place_bad_demo.gif"><img alt="GR-1 humanoid robot performing a bad pick and place demonstration" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place_bad_demo.gif" style="width: 49%;" /></a></p>
<p class="centered">
<strong>Left: A good human demonstration with smooth and steady motion. Right: A bad demonstration with jerky and exaggerated motion.</strong></p><p>Collect five demonstrations by running the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/tools/record_demos.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-GR1T2-Abs-v0<span class="w"> </span><span class="se">\</span>
--teleop_device<span class="w"> </span>handtracking<span class="w"> </span><span class="se">\</span>
--dataset_file<span class="w"> </span>./datasets/dataset_gr1.hdf5<span class="w"> </span><span class="se">\</span>
--num_demos<span class="w"> </span><span class="m">5</span><span class="w"> </span>--enable_pinocchio
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We also provide a GR-1 pick and place task with waist degrees-of-freedom enabled <code class="docutils literal notranslate"><span class="pre">Isaac-PickPlace-GR1T2-WaistEnabled-Abs-v0</span></code> (see <a class="reference internal" href="../environments.html#environments"><span class="std std-ref">Available Environments</span></a> for details on the available environments, including the GR1 Waist Enabled variant). The same command above applies but with the task name changed to <code class="docutils literal notranslate"><span class="pre">Isaac-PickPlace-GR1T2-WaistEnabled-Abs-v0</span></code>.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If a demo fails during data collection, the environment can be reset using the teleoperation controls panel in the XR teleop client
on the Apple Vision Pro or via voice control by saying “reset”. See <a class="reference internal" href="../../how-to/cloudxr_teleoperation.html#teleoperate-apple-vision-pro"><span class="std std-ref">Teleoperate an Isaac Lab Robot with Apple Vision Pro</span></a> for more details.</p>
<p>The robot uses simplified collision meshes for physics calculations that differ from the detailed visual meshes displayed in the simulation. Due to this difference, you may occasionally observe visual artifacts where parts of the robot appear to penetrate other objects or itself, even though proper collision handling is occurring in the physics simulation.</p>
</div>
<p>You can replay the collected demonstrations by running the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/tools/replay_demos.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-GR1T2-Abs-v0<span class="w"> </span><span class="se">\</span>
--dataset_file<span class="w"> </span>./datasets/dataset_gr1.hdf5<span class="w"> </span>--enable_pinocchio
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Non-determinism may be observed during replay as physics in IsaacLab are not determimnistically reproducible when using <code class="docutils literal notranslate"><span class="pre">env.reset</span></code>.</p>
</div>
</section>
<section id="annotate-the-demonstrations">
<h4>Annotate the demonstrations<a class="headerlink" href="#annotate-the-demonstrations" title="Permalink to this heading">#</a></h4>
<p>Unlike the prior Franka stacking task, the GR-1 pick and place task uses manual annotation to define subtasks.</p>
<p>The pick and place task has one subtask for the left arm (pick) and two subtasks for the right arm (idle, place).
Annotations denote the end of a subtask. For the pick and place task, this means there are no annotations for the left arm and one annotation for the right arm (the end of the final subtask is always implicit).</p>
<p>Each demo requires a single annotation between the first and second subtask of the right arm. This annotation (“S” button press) should be done when the right robot arm finishes the “idle” subtask and begins to
move towards the target object. An example of a correct annotation is shown below:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../../../_images/gr-1_pick_place_annotation.jpg"><img alt="../../../_images/gr-1_pick_place_annotation.jpg" src="../../../_images/gr-1_pick_place_annotation.jpg" style="width: 100%;" /></a>
</figure>
<p>Annotate the demonstrations by running the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/annotate_demos.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-GR1T2-Abs-Mimic-v0<span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/dataset_gr1.hdf5<span class="w"> </span><span class="se">\</span>
--output_file<span class="w"> </span>./datasets/dataset_annotated_gr1.hdf5<span class="w"> </span>--enable_pinocchio
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The script prints the keyboard commands for manual annotation and the current subtask being annotated:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Annotating episode #0 (demo_0)
   Playing the episode for subtask annotations for eef &quot;right&quot;.
   Subtask signals to annotate:
      - Termination:      [&#39;idle_right&#39;]

   Press &quot;N&quot; to begin.
   Press &quot;B&quot; to pause.
   Press &quot;S&quot; to annotate subtask signals.
   Press &quot;Q&quot; to skip the episode.
</pre></div>
</div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If the object does not get placed in the bin during annotation, you can press “N” to replay the episode and annotate again. Or you can press “Q” to skip the episode and annotate the next one.</p>
</div>
</section>
</section>
<section id="generate-the-dataset">
<h3>Generate the dataset<a class="headerlink" href="#generate-the-dataset" title="Permalink to this heading">#</a></h3>
<p>If you skipped the prior collection and annotation step, download the pre-recorded annotated dataset <code class="docutils literal notranslate"><span class="pre">dataset_annotated_gr1.hdf5</span></code> from
here: <a class="reference external" href="https://omniverse-content-production.s3-us-west-2.amazonaws.com/Assets/Isaac/5.1/Isaac/IsaacLab/Mimic/pick_place_datasets/dataset_annotated_gr1.hdf5">[Annotated GR1 Dataset]</a>.
Place the file under <code class="docutils literal notranslate"><span class="pre">IsaacLab/datasets</span></code> and run the following command to generate a new dataset with 1000 demonstrations.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/generate_dataset.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span>--headless<span class="w"> </span>--num_envs<span class="w"> </span><span class="m">20</span><span class="w"> </span>--generation_num_trials<span class="w"> </span><span class="m">1000</span><span class="w"> </span>--enable_pinocchio<span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/dataset_annotated_gr1.hdf5<span class="w"> </span>--output_file<span class="w"> </span>./datasets/generated_dataset_gr1.hdf5
</pre></div>
</div>
</section>
<section id="train-a-policy">
<h3>Train a policy<a class="headerlink" href="#train-a-policy" title="Permalink to this heading">#</a></h3>
<p>Use <a class="reference external" href="https://robomimic.github.io/">Robomimic</a> to train a policy for the generated dataset.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/train.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-GR1T2-Abs-v0<span class="w"> </span>--algo<span class="w"> </span>bc<span class="w"> </span><span class="se">\</span>
--normalize_training_actions<span class="w"> </span><span class="se">\</span>
--dataset<span class="w"> </span>./datasets/generated_dataset_gr1.hdf5
</pre></div>
</div>
<p>The training script will normalize the actions in the dataset to the range [-1, 1].
The normalization parameters are saved in the model directory under <code class="docutils literal notranslate"><span class="pre">PATH_TO_MODEL_DIRECTORY/logs/normalization_params.txt</span></code>.
Record the normalization parameters for later use in the visualization step.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By default the trained models and logs will be saved to <code class="docutils literal notranslate"><span class="pre">IssacLab/logs/robomimic</span></code>.</p>
</div>
</section>
<section id="visualize-the-results">
<h3>Visualize the results<a class="headerlink" href="#visualize-the-results" title="Permalink to this heading">#</a></h3>
<p>Visualize the results of the trained policy by running the following command, using the normalization parameters recorded in the prior training step:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/play.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--enable_pinocchio<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-GR1T2-Abs-v0<span class="w"> </span><span class="se">\</span>
--num_rollouts<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
--horizon<span class="w"> </span><span class="m">400</span><span class="w"> </span><span class="se">\</span>
--norm_factor_min<span class="w"> </span>&lt;NORM_FACTOR_MIN&gt;<span class="w"> </span><span class="se">\</span>
--norm_factor_max<span class="w"> </span>&lt;NORM_FACTOR_MAX&gt;<span class="w"> </span><span class="se">\</span>
--checkpoint<span class="w"> </span>/PATH/TO/desired_model_checkpoint.pth
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Change the <code class="docutils literal notranslate"><span class="pre">NORM_FACTOR</span></code> in the above command with the values generated in the training step.</p>
</div>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place_policy.gif"><img alt="GR-1 humanoid robot performing a pick and place task" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place_policy.gif" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">The trained policy performing the pick and place task in Isaac Lab.</span><a class="headerlink" href="#id4" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="demo-2-data-generation-and-policy-training-for-humanoid-robot-locomanipulation-with-unitree-g1">
<h2>Demo 2: Data Generation and Policy Training for Humanoid Robot Locomanipulation with Unitree G1<a class="headerlink" href="#demo-2-data-generation-and-policy-training-for-humanoid-robot-locomanipulation-with-unitree-g1" title="Permalink to this heading">#</a></h2>
<p>In this demo, we showcase the integration of locomotion and manipulation capabilities within a single humanoid robot system.
This locomanipulation environment enables data collection for complex tasks that combine navigation and object manipulation.
The demonstration follows a multi-step process: first, it generates pick and place tasks similar to Demo 1, then introduces
a navigation component that uses specialized scripts to generate scenes where the humanoid robot must move from point A to point B.
The robot picks up an object at the initial location (point A) and places it at the target destination (point B).</p>
<figure class="align-center">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/locomanipulation-g-1_steering_wheel_pick_place.gif"><img alt="G1 humanoid robot with locomanipulation performing a pick and place task" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/locomanipulation-g-1_steering_wheel_pick_place.gif" style="width: 100%;" /></a>
</figure>
<section id="generate-the-manipulation-dataset">
<h3>Generate the manipulation dataset<a class="headerlink" href="#generate-the-manipulation-dataset" title="Permalink to this heading">#</a></h3>
<p>The same data generation and policy training steps from Demo 1.0 can be applied to the G1 humanoid robot with locomanipulation capabilities.
This demonstration shows how to train a G1 robot to perform pick and place tasks with full-body locomotion and manipulation.</p>
<p>The process follows the same workflow as Demo 1.0, but uses the <code class="docutils literal notranslate"><span class="pre">Isaac-PickPlace-Locomanipulation-G1-Abs-v0</span></code> task environment.</p>
<p>Follow the same data collection, annotation, and generation process as demonstrated in Demo 1.0, but adapted for the G1 locomanipulation task.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>If desired, data collection and annotation can be done using the same commands as the prior examples for validation of the dataset.</p>
<p>The G1 robot with locomanipulation capabilities combines full-body locomotion with manipulation to perform pick and place tasks.</p>
<p><strong>Note that the following commands are only for your reference and dataset validation purposes - they are not required for this demo.</strong></p>
<p>To collect demonstrations:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/tools/record_demos.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-Locomanipulation-G1-Abs-v0<span class="w"> </span><span class="se">\</span>
--teleop_device<span class="w"> </span>handtracking<span class="w"> </span><span class="se">\</span>
--dataset_file<span class="w"> </span>./datasets/dataset_g1_locomanip.hdf5<span class="w"> </span><span class="se">\</span>
--num_demos<span class="w"> </span><span class="m">5</span><span class="w"> </span>--enable_pinocchio
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Depending on how the Apple Vision Pro app was initialized, the hands of the operator might be very far up or far down compared to the hands of the G1 robot. If this is the case, you can click <strong>Stop AR</strong> in the AR tab in Isaac Lab, and move the AR Anchor prim. Adjust it down to bring the hands of the operator lower, and up to bring them higher. Click <strong>Start AR</strong> to resume teleoperation session. Make sure to match the hands of the robot before clicking <strong>Play</strong> in the Apple Vision Pro, otherwise there will be an undesired large force generated initially.</p>
</div>
<p>You can replay the collected demonstrations by running:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/tools/replay_demos.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-Locomanipulation-G1-Abs-v0<span class="w"> </span><span class="se">\</span>
--dataset_file<span class="w"> </span>./datasets/dataset_g1_locomanip.hdf5<span class="w"> </span>--enable_pinocchio
</pre></div>
</div>
<p>To annotate the demonstrations:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/annotate_demos.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-Locomanipulation-G1-Abs-Mimic-v0<span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/dataset_g1_locomanip.hdf5<span class="w"> </span><span class="se">\</span>
--output_file<span class="w"> </span>./datasets/dataset_annotated_g1_locomanip.hdf5<span class="w"> </span>--enable_pinocchio
</pre></div>
</div>
</div>
<p>If you skipped the prior collection and annotation step, download the pre-recorded annotated dataset <code class="docutils literal notranslate"><span class="pre">dataset_annotated_g1_locomanip.hdf5</span></code> from
here: <a class="reference external" href="https://omniverse-content-production.s3-us-west-2.amazonaws.com/Assets/Isaac/5.1/Isaac/IsaacLab/Mimic/pick_place_datasets/dataset_annotated_g1_locomanip.hdf5">[Annotated G1 Dataset]</a>.
Place the file under <code class="docutils literal notranslate"><span class="pre">IsaacLab/datasets</span></code> and run the following command to generate a new dataset with 1000 demonstrations.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/generate_dataset.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span>--headless<span class="w"> </span>--num_envs<span class="w"> </span><span class="m">20</span><span class="w"> </span>--generation_num_trials<span class="w"> </span><span class="m">1000</span><span class="w"> </span>--enable_pinocchio<span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/dataset_annotated_g1_locomanip.hdf5<span class="w"> </span>--output_file<span class="w"> </span>./datasets/generated_dataset_g1_locomanip.hdf5
</pre></div>
</div>
</section>
<section id="train-a-manipulation-only-policy">
<h3>Train a manipulation-only policy<a class="headerlink" href="#train-a-manipulation-only-policy" title="Permalink to this heading">#</a></h3>
<p>At this point you can train a policy that only performs manipulation tasks using the generated dataset:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/train.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-Locomanipulation-G1-Abs-v0<span class="w"> </span>--algo<span class="w"> </span>bc<span class="w"> </span><span class="se">\</span>
--normalize_training_actions<span class="w"> </span><span class="se">\</span>
--dataset<span class="w"> </span>./datasets/generated_dataset_g1_locomanip.hdf5
</pre></div>
</div>
</section>
<section id="id1">
<h3>Visualize the results<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<p>Visualize the trained policy performance:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/play.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--enable_pinocchio<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-Locomanipulation-G1-Abs-v0<span class="w"> </span><span class="se">\</span>
--num_rollouts<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
--horizon<span class="w"> </span><span class="m">400</span><span class="w"> </span><span class="se">\</span>
--norm_factor_min<span class="w"> </span>&lt;NORM_FACTOR_MIN&gt;<span class="w"> </span><span class="se">\</span>
--norm_factor_max<span class="w"> </span>&lt;NORM_FACTOR_MAX&gt;<span class="w"> </span><span class="se">\</span>
--checkpoint<span class="w"> </span>/PATH/TO/desired_model_checkpoint.pth
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Change the <code class="docutils literal notranslate"><span class="pre">NORM_FACTOR</span></code> in the above command with the values generated in the training step.</p>
</div>
<figure class="align-center" id="id5">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/locomanipulation-g-1_steering_wheel_pick_place.gif"><img alt="G1 humanoid robot performing a pick and place task" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/locomanipulation-g-1_steering_wheel_pick_place.gif" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">The trained policy performing the pick and place task in Isaac Lab.</span><a class="headerlink" href="#id5" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="generate-the-dataset-with-manipulation-and-point-to-point-navigation">
<h3>Generate the dataset with manipulation and point-to-point navigation<a class="headerlink" href="#generate-the-dataset-with-manipulation-and-point-to-point-navigation" title="Permalink to this heading">#</a></h3>
<p>To create a comprehensive locomanipulation dataset that combines both manipulation and navigation capabilities, you can generate a navigation dataset using the manipulation dataset from the previous step as input.</p>
<figure class="align-center" id="id6">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/disjoint_navigation.gif"><img alt="G1 humanoid robot combining navigation with locomanipulation" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/disjoint_navigation.gif" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">G1 humanoid robot performing locomanipulation with navigation capabilities.</span><a class="headerlink" href="#id6" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The locomanipulation dataset generation process takes the previously generated manipulation dataset and creates scenarios where the robot must navigate from one location to another while performing manipulation tasks. This creates a more complex dataset that includes both locomotion and manipulation behaviors.</p>
<p>To generate the locomanipulation dataset, use the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>scripts/imitation_learning/locomanipulation_sdg/generate_data.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--kit_args<span class="o">=</span><span class="s2">&quot;--enable isaacsim.replicator.mobility_gen&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task<span class="o">=</span><span class="s2">&quot;Isaac-G1-SteeringWheel-Locomanipulation&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span>./datasets/generated_dataset_g1_locomanip.hdf5<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_runs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lift_step<span class="w"> </span><span class="m">70</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--navigate_step<span class="w"> </span><span class="m">120</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--enable_pinocchio<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_file<span class="w"> </span>./datasets/generated_dataset_g1_locomanipulation_sdg.hdf5<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--enable_cameras
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The input dataset (<code class="docutils literal notranslate"><span class="pre">--dataset</span></code>) should be the manipulation dataset generated in the previous step. You can specify any output filename using the <code class="docutils literal notranslate"><span class="pre">--output_file_name</span></code> parameter.</p>
</div>
<p>The key parameters for locomanipulation dataset generation are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--lift_step</span> <span class="pre">70</span></code>: Number of steps for the lifting phase of the manipulation task.  This should mark the point immediately after the robot has grasped the object.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--navigate_step</span> <span class="pre">120</span></code>: Number of steps for the navigation phase between locations.  This should make the point where the robot has lifted the object and is ready to walk.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--output_file</span></code>: Name of the output dataset file</p></li>
</ul>
<p>This process creates a dataset where the robot performs the manipulation task at different locations, requiring it to navigate between points while maintaining the learned manipulation behaviors. The resulting dataset can be used to train policies that combine both locomotion and manipulation capabilities.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can visualize the robot trajectory results with the following script command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/locomanipulation_sdg/plot_navigation_trajectory.py<span class="w"> </span>--input_file<span class="w"> </span>datasets/generated_dataset_g1_locomanipulation_sdg.hdf5<span class="w"> </span>--output_dir<span class="w"> </span>/PATH/TO/DESIRED_OUTPUT_DIR
</pre></div>
</div>
</div>
<p>The data generated from this locomanipulation pipeline can also be used to finetune an imitation learning policy using GR00T N1.5.  To do this,
you may convert the generated dataset to LeRobot format as expected by GR00T N1.5, and then run the finetuning script provided
in the GR00T N1.5 repository.  An example closed-loop policy rollout is shown in the video below:</p>
<figure class="align-center" id="id7">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/locomanipulation_sdg_disjoint_nav_groot_policy_4x.gif"><img alt="Simulation rollout of GR00T N1.5 policy finetuned for locomanipulation" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/locomanipulation_sdg_disjoint_nav_groot_policy_4x.gif" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">Simulation rollout of GR00T N1.5 policy finetuned for locomanipulation.</span><a class="headerlink" href="#id7" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The policy shown above uses the camera image, hand poses, hand joint positions, object pose, and base goal pose as inputs.
The output of the model is the target base velocity, hand poses, and hand joint positions for the next several timesteps.</p>
</section>
</section>
<section id="demo-3-visuomotor-policy-for-a-humanoid-robot">
<h2>Demo 3: Visuomotor Policy for a Humanoid Robot<a class="headerlink" href="#demo-3-visuomotor-policy-for-a-humanoid-robot" title="Permalink to this heading">#</a></h2>
<figure class="align-center">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_nut_pouring_policy.gif"><img alt="GR-1 humanoid robot performing a pouring task" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_nut_pouring_policy.gif" style="width: 100%;" /></a>
</figure>
<section id="download-the-dataset">
<h3>Download the Dataset<a class="headerlink" href="#download-the-dataset" title="Permalink to this heading">#</a></h3>
<p>Download the pre-generated dataset from <a class="reference external" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/dataset/generated_dataset_gr1_nut_pouring.hdf5">here</a> and place it under <code class="docutils literal notranslate"><span class="pre">IsaacLab/datasets/generated_dataset_gr1_nut_pouring.hdf5</span></code>
(<strong>Note: The dataset size is approximately 12GB</strong>). The dataset contains 1000 demonstrations of a humanoid robot performing a pouring/placing task that was
generated using Isaac Lab Mimic for the <code class="docutils literal notranslate"><span class="pre">Isaac-NutPour-GR1T2-Pink-IK-Abs-Mimic-v0</span></code> task.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>If desired, data collection, annotation, and generation can be done using the same commands as the prior examples.</p>
<p>The robot first picks up the red beaker and pours the contents into the yellow bowl.
Then, it drops the red beaker into the blue bin. Lastly, it places the yellow bowl onto the white scale.
See the video in the <a class="reference internal" href="#visualize-results-demo-2"><span class="std std-ref">Visualize the results</span></a> section below for a visual demonstration of the task.</p>
<p><strong>The success criteria for this task requires the red beaker to be placed in the blue bin, the green nut to be in the yellow bowl,
and the yellow bowl to be placed on top of the white scale.</strong></p>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p><strong>The following commands are only for your reference and are not required for this demo.</strong></p>
</div>
<p>To collect demonstrations:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/tools/record_demos.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-NutPour-GR1T2-Pink-IK-Abs-v0<span class="w"> </span><span class="se">\</span>
--teleop_device<span class="w"> </span>handtracking<span class="w"> </span><span class="se">\</span>
--dataset_file<span class="w"> </span>./datasets/dataset_gr1_nut_pouring.hdf5<span class="w"> </span><span class="se">\</span>
--num_demos<span class="w"> </span><span class="m">5</span><span class="w"> </span>--enable_pinocchio
</pre></div>
</div>
<p>Since this is a visuomotor environment, the <code class="docutils literal notranslate"><span class="pre">--enable_cameras</span></code> flag must be added to the annotation and data generation commands.</p>
<p>To annotate the demonstrations:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/annotate_demos.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--enable_cameras<span class="w"> </span><span class="se">\</span>
--rendering_mode<span class="w"> </span>balanced<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-NutPour-GR1T2-Pink-IK-Abs-Mimic-v0<span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/dataset_gr1_nut_pouring.hdf5<span class="w"> </span><span class="se">\</span>
--output_file<span class="w"> </span>./datasets/dataset_annotated_gr1_nut_pouring.hdf5<span class="w"> </span>--enable_pinocchio
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>There are multiple right eef annotations for this task. Annotations for subtasks for the same eef cannot have the same action index.
Make sure to annotate the right eef subtasks with different action indices.</p>
</div>
<p>To generate the dataset:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/generate_dataset.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--headless<span class="w"> </span><span class="se">\</span>
--enable_pinocchio<span class="w"> </span><span class="se">\</span>
--enable_cameras<span class="w"> </span><span class="se">\</span>
--rendering_mode<span class="w"> </span>balanced<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-NutPour-GR1T2-Pink-IK-Abs-Mimic-v0<span class="w"> </span><span class="se">\</span>
--generation_num_trials<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="se">\</span>
--num_envs<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/dataset_annotated_gr1_nut_pouring.hdf5<span class="w"> </span><span class="se">\</span>
--output_file<span class="w"> </span>./datasets/generated_dataset_gr1_nut_pouring.hdf5
</pre></div>
</div>
</div>
</section>
<section id="id2">
<h3>Train a policy<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>Use <a class="reference external" href="https://robomimic.github.io/">Robomimic</a> to train a visuomotor BC agent for the task.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/train.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-NutPour-GR1T2-Pink-IK-Abs-v0<span class="w"> </span>--algo<span class="w"> </span>bc<span class="w"> </span><span class="se">\</span>
--normalize_training_actions<span class="w"> </span><span class="se">\</span>
--dataset<span class="w"> </span>./datasets/generated_dataset_gr1_nut_pouring.hdf5
</pre></div>
</div>
<p>The training script will normalize the actions in the dataset to the range [-1, 1].
The normalization parameters are saved in the model directory under <code class="docutils literal notranslate"><span class="pre">PATH_TO_MODEL_DIRECTORY/logs/normalization_params.txt</span></code>.
Record the normalization parameters for later use in the visualization step.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By default the trained models and logs will be saved to <code class="docutils literal notranslate"><span class="pre">IsaacLab/logs/robomimic</span></code>.</p>
</div>
<p>You can also post-train a <a class="reference external" href="https://github.com/NVIDIA/Isaac-GR00T">GR00T</a> foundation model to deploy a Vision-Language-Action policy for the task.</p>
<p>Please refer to the <a class="reference external" href="https://github.com/isaac-sim/IsaacLabEvalTasks/">IsaacLabEvalTasks</a> repository for more details.</p>
</section>
<section id="visualize-results-demo-2">
<span id="id3"></span><h3>Visualize the results<a class="headerlink" href="#visualize-results-demo-2" title="Permalink to this heading">#</a></h3>
<p>Visualize the results of the trained policy by running the following command, using the normalization parameters recorded in the prior training step:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/play.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--enable_pinocchio<span class="w"> </span><span class="se">\</span>
--enable_cameras<span class="w"> </span><span class="se">\</span>
--rendering_mode<span class="w"> </span>balanced<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-NutPour-GR1T2-Pink-IK-Abs-v0<span class="w"> </span><span class="se">\</span>
--num_rollouts<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
--horizon<span class="w"> </span><span class="m">350</span><span class="w"> </span><span class="se">\</span>
--norm_factor_min<span class="w"> </span>&lt;NORM_FACTOR_MIN&gt;<span class="w"> </span><span class="se">\</span>
--norm_factor_max<span class="w"> </span>&lt;NORM_FACTOR_MAX&gt;<span class="w"> </span><span class="se">\</span>
--checkpoint<span class="w"> </span>/PATH/TO/desired_model_checkpoint.pth
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Change the <code class="docutils literal notranslate"><span class="pre">NORM_FACTOR</span></code> in the above command with the values generated in the training step.</p>
</div>
<figure class="align-center" id="id8">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_nut_pouring_policy.gif"><img alt="GR-1 humanoid robot performing a pouring task" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_nut_pouring_policy.gif" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">The trained visuomotor policy performing the pouring task in Isaac Lab.</span><a class="headerlink" href="#id8" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="common-pitfalls-when-generating-data">
<h2>Common Pitfalls when Generating Data<a class="headerlink" href="#common-pitfalls-when-generating-data" title="Permalink to this heading">#</a></h2>
<p><strong>Demonstrations are too long:</strong></p>
<ul class="simple">
<li><p>Longer time horizon is harder to learn for a policy</p></li>
<li><p>Start close to the first object and minimize motions</p></li>
</ul>
<p><strong>Demonstrations are not smooth:</strong></p>
<ul class="simple">
<li><p>Irregular motion is hard for policy to decipher</p></li>
<li><p>Better teleop devices result in better data (i.e. SpaceMouse is better than Keyboard)</p></li>
</ul>
<p><strong>Pauses in demonstrations:</strong></p>
<ul class="simple">
<li><p>Pauses are difficult to learn</p></li>
<li><p>Keep the human motions smooth and fluid</p></li>
</ul>
<p><strong>Excessive number of subtasks:</strong></p>
<ul class="simple">
<li><p>Minimize the number of defined subtasks for completing a given task</p></li>
<li><p>Less subtacks results in less stitching of trajectories, yielding higher data generation success rate</p></li>
</ul>
<p><strong>Lack of action noise:</strong></p>
<ul class="simple">
<li><p>Action noise makes policies more robust</p></li>
</ul>
<p><strong>Recording cropped too tight:</strong></p>
<ul class="simple">
<li><p>If recording stops on the frame the success term triggers, it may not re-trigger during replay</p></li>
<li><p>Allow for some buffer at the end of recording</p></li>
</ul>
<p><strong>Non-deterministic replay:</strong></p>
<ul class="simple">
<li><p>Physics in IsaacLab are not deterministically reproducible when using <code class="docutils literal notranslate"><span class="pre">env.reset</span></code> so demonstrations may fail on replay</p></li>
<li><p>Collect more human demos than needed, use the ones that succeed during annotation</p></li>
<li><p>All data in Isaac Lab Mimic generated HDF5 file represent a successful demo and can be used for training (even if non-determinism causes failure when replayed)</p></li>
</ul>
</section>
<section id="creating-your-own-isaac-lab-mimic-compatible-environments">
<h2>Creating Your Own Isaac Lab Mimic Compatible Environments<a class="headerlink" href="#creating-your-own-isaac-lab-mimic-compatible-environments" title="Permalink to this heading">#</a></h2>
<section id="how-it-works">
<h3>How it works<a class="headerlink" href="#how-it-works" title="Permalink to this heading">#</a></h3>
<p>Isaac Lab Mimic works by splitting the input demonstrations into subtasks. Subtasks are user-defined segments in the demonstrations that are common to all demonstrations. Examples for subtasks are “grasp an object”, “move end effector to some pre-defined position”, “release object” etc.. Note that most subtasks are defined with respect to some object that the robot interacts with.</p>
<p>Subtasks need to be defined, and then annotated for each input demonstration. Annotation can either happen algorithmically by defining heuristics for subtask detection, as was done in the example above, or it can be done manually.</p>
<p>With subtasks defined and annotated, Isaac Lab Mimic utilizes a small number of helper methods to then transform the subtask segments, and generate new demonstrations by stitching them together to match the new task at hand.</p>
<p>For each thusly generated candidate demonstration, Isaac Lab Mimic uses a boolean success criteria to determine whether the demonstration succeeded in performing the task, and if so, add it to the output dataset. Success rate of candidate demonstrations can be as high as 70% in simple cases, and as low as &lt;1%, depending on the difficulty of the task, and the complexity of the robot itself.</p>
</section>
<section id="configuration-and-subtask-definition">
<h3>Configuration and subtask definition<a class="headerlink" href="#configuration-and-subtask-definition" title="Permalink to this heading">#</a></h3>
<p>Subtasks, among other configuration settings for Isaac Lab Mimic, are defined in a Mimic compatible environment configuration class that is created by extending the existing environment config with additional Mimic required parameters.</p>
<p>All Mimic required config parameters are specified in the <a class="reference internal" href="../../api/lab/isaaclab.envs.html#isaaclab.envs.MimicEnvCfg" title="isaaclab.envs.MimicEnvCfg"><code class="xref py py-class docutils literal notranslate"><span class="pre">MimicEnvCfg</span></code></a> class.</p>
<p>The config class <a class="reference internal" href="../../api/lab_mimic/isaaclab_mimic.envs.html#isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg" title="isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg"><code class="xref py py-class docutils literal notranslate"><span class="pre">FrankaCubeStackIKRelMimicEnvCfg</span></code></a> serves as an example of creating a Mimic compatible environment config class for the Franka stacking task that was used in the examples above.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">DataGenConfig</span></code> member contains various parameters that influence how data is generated. It is initially sufficient to just set the <code class="docutils literal notranslate"><span class="pre">name</span></code> parameter, and revise the rest later.</p>
<p>Subtasks are a list of <a class="reference internal" href="../../api/lab/isaaclab.envs.html#isaaclab.envs.SubTaskConfig" title="isaaclab.envs.SubTaskConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">SubTaskConfig</span></code></a> objects, of which the most important members are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">object_ref</span></code> is the object that is being interacted with. This will be used to adjust motions relative to this object during data generation. Can be <code class="docutils literal notranslate"><span class="pre">None</span></code> if the current subtask does not involve any object.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">subtask_term_signal</span></code> is the ID of the signal indicating whether the subtask is active or not.</p></li>
</ul>
<p>For multi end-effector environments, subtask ordering between end-effectors can be enforced by specifying subtask constraints. These constraints are defined in the <a class="reference internal" href="../../api/lab/isaaclab.envs.html#isaaclab.envs.SubTaskConstraintConfig" title="isaaclab.envs.SubTaskConstraintConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">SubTaskConstraintConfig</span></code></a> class.</p>
</section>
<section id="subtask-annotation">
<h3>Subtask annotation<a class="headerlink" href="#subtask-annotation" title="Permalink to this heading">#</a></h3>
<p>Once the subtasks are defined, they need to be annotated in the source data. There are two methods to annotate source demonstrations for subtask boundaries: Manual annotation or using heuristics.</p>
<p>It is often easiest to perform manual annotations, since the number of input demonstrations is usually very small. To perform manual annotations, use the <code class="docutils literal notranslate"><span class="pre">annotate_demos.py</span></code> script without the <code class="docutils literal notranslate"><span class="pre">--auto</span></code> flag. Then press <code class="docutils literal notranslate"><span class="pre">B</span></code> to pause, <code class="docutils literal notranslate"><span class="pre">N</span></code> to continue, and <code class="docutils literal notranslate"><span class="pre">S</span></code> to annotate a subtask boundary.</p>
<p>For more accurate boundaries, or to speed up repeated processing of a given task for experiments, heuristics can be implemented to perform the same task. Heuristics are observations in the environment. An example how to add subtask terms can be found in <code class="docutils literal notranslate"><span class="pre">source/isaaclab_tasks/isaaclab_tasks/manager_based/manipulation/stack/stack_env_cfg.py</span></code>, where they are added as an observation group called <code class="docutils literal notranslate"><span class="pre">SubtaskCfg</span></code>. This example is using prebuilt heuristics, but custom heuristics are easily implemented.</p>
</section>
<section id="helpers-for-demonstration-generation">
<h3>Helpers for demonstration generation<a class="headerlink" href="#helpers-for-demonstration-generation" title="Permalink to this heading">#</a></h3>
<p>Helpers needed for Isaac Lab Mimic are defined in the environment. All tasks that are to be used with Isaac Lab Mimic are derived from the <a class="reference internal" href="../../api/lab/isaaclab.envs.html#isaaclab.envs.ManagerBasedRLMimicEnv" title="isaaclab.envs.ManagerBasedRLMimicEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">ManagerBasedRLMimicEnv</span></code></a> base class, and must implement the following functions:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">get_robot_eef_pose</span></code>: Returns the current robot end effector pose in the same frame as used by the robot end effector controller.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">target_eef_pose_to_action</span></code>: Takes a target pose and a gripper action for the end effector controller and returns an action which achieves the target pose.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">action_to_target_eef_pose</span></code>: Takes an action and returns a target pose for the end effector controller.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">actions_to_gripper_actions</span></code>: Takes a sequence of actions and returns the gripper actuation part of the actions.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_object_poses</span></code>: Returns the pose of each object in the scene that is used for data generation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_subtask_term_signals</span></code>: Returns a dictionary of binary flags for each subtask in a task. The flag of true is set when the subtask has been completed and false otherwise.</p></li>
</ul>
<p>The class <a class="reference internal" href="../../api/lab_mimic/isaaclab_mimic.envs.html#isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv" title="isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">FrankaCubeStackIKRelMimicEnv</span></code></a> shows an example of creating a Mimic compatible environment from an existing Isaac Lab environment.</p>
</section>
<section id="registering-the-environment">
<h3>Registering the environment<a class="headerlink" href="#registering-the-environment" title="Permalink to this heading">#</a></h3>
<p>Once both Mimic compatible environment and environment config classes have been created, a new Mimic compatible environment can be registered using <code class="docutils literal notranslate"><span class="pre">gym.register</span></code>. For the Franka stacking task in the examples above, the Mimic environment is registered as <code class="docutils literal notranslate"><span class="pre">Isaac-Stack-Cube-Franka-IK-Rel-Mimic-v0</span></code>.</p>
<p>The registered environment is now ready to be used with Isaac Lab Mimic.</p>
</section>
</section>
<section id="tips-for-successful-data-generation-with-isaac-lab-mimic">
<h2>Tips for Successful Data Generation with Isaac Lab Mimic<a class="headerlink" href="#tips-for-successful-data-generation-with-isaac-lab-mimic" title="Permalink to this heading">#</a></h2>
<section id="splitting-subtasks">
<h3>Splitting subtasks<a class="headerlink" href="#splitting-subtasks" title="Permalink to this heading">#</a></h3>
<p>A general rule of thumb is to split the task into as few subtasks as possible, while still being able to complete the task. Isaac Lab Mimic data generation uses linear interpolation to bridge and stitch together subtask segments.
More subtasks result in more stitching of trajectories which can result in less smooth motions and more failed demonstrations. For this reason, it is often best to annoatate subtask boundaries where the robot’s motion is unlikely to collide with other objects.</p>
<p>For example, in the scenario below, there is a subtask partition after the robot’s left arm grasps the object. On the left, the subtask annotation is marked immediately after the grasp, while on the right, the annotation is marked after the robot has grasped and lifted the object.
In the left case, the interpolation causes the robot’s left arm to collide with the table and it’s motion lags while on the right the motion is continuous and smooth.</p>
<figure class="align-center">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/lagging_subtask.gif"><img alt="Subtask splitting example" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/lagging_subtask.gif" style="width: 99%;" /></a>
</figure>
<p class="centered">
<strong>Motion lag/collision caused by poor subtask splitting (left)</strong></p></section>
<section id="selecting-number-of-interpolation-steps">
<h3>Selecting number of interpolation steps<a class="headerlink" href="#selecting-number-of-interpolation-steps" title="Permalink to this heading">#</a></h3>
<p>The number of interpolation steps between subtask segments can be specified in the <a class="reference internal" href="../../api/lab/isaaclab.envs.html#isaaclab.envs.SubTaskConfig" title="isaaclab.envs.SubTaskConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">SubTaskConfig</span></code></a> class. Once transformed, the subtask segments don’t start/end at the same spot, thus to create a continuous motion, Isaac Lab Mimic
will apply linear interpolation between the last point of the previous subtask and the first point of the next subtask.</p>
<p>The number of interpolation steps can be tuned to control the smoothness of the generated demonstrations during this stitching process.
The appropriate number of interpolation steps depends on the speed of the robot and the complexity of the task. A complex task with a large object reset distribution will have larger gaps between subtask segments and require more interpolation steps to create a smooth motion.
Alternatively, a task with small gaps between subtask segments should use a small number of interpolation steps to avoid unnecessary motion lag caused by too many steps.</p>
<p>An example of how the number of interpolation steps can affect the generated demonstrations is shown below.
In the example, an interpolation is applied to the right arm of the robot to bridge the gap between the left arm’s grasp and the right arm’s placement. With 0 steps, the right arm exhibits a jerky jump in motion while with 20 steps, the motion is laggy. With 5 steps, the motion is
smooth and natural.</p>
<p><a class="reference internal" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/0_interpolation_steps.gif"><img alt="GR-1 robot with 0 interpolation steps" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/0_interpolation_steps.gif" style="width: 32%;" /></a> <a class="reference internal" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/5_interpolation_steps.gif"><img alt="GR-1 robot with 5 interpolation steps" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/5_interpolation_steps.gif" style="width: 32%;" /></a> <a class="reference internal" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/20_interpolation_steps.gif"><img alt="GR-1 robot with 20 interpolation steps" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/20_interpolation_steps.gif" style="width: 32%;" /></a></p>
<p class="centered">
<strong>Left: 0 steps. Middle: 5 steps. Right: 20 steps.</strong></p></section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Imitation Learning</p>
      </div>
    </a>
    <a class="right-next"
       href="augmented_imitation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Augmented Imitation Learning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teleoperation">Teleoperation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imitation-learning-with-isaac-lab-mimic">Imitation Learning with Isaac Lab Mimic</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#collecting-demonstrations">Collecting demonstrations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-recorded-demonstrations">Pre-recorded demonstrations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-additional-demonstrations-with-isaac-lab-mimic">Generating additional demonstrations with Isaac Lab Mimic</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robomimic-setup">Robomimic setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-an-agent">Training an agent</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-results">Visualizing results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-1-data-generation-and-policy-training-for-a-humanoid-robot">Demo 1: Data Generation and Policy Training for a Humanoid Robot</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-collect-and-annotate-demonstrations">Optional: Collect and annotate demonstrations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#collect-human-demonstrations">Collect human demonstrations</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#annotate-the-demonstrations">Annotate the demonstrations</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-dataset">Generate the dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-policy">Train a policy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-results">Visualize the results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-2-data-generation-and-policy-training-for-humanoid-robot-locomanipulation-with-unitree-g1">Demo 2: Data Generation and Policy Training for Humanoid Robot Locomanipulation with Unitree G1</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-manipulation-dataset">Generate the manipulation dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-manipulation-only-policy">Train a manipulation-only policy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Visualize the results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-dataset-with-manipulation-and-point-to-point-navigation">Generate the dataset with manipulation and point-to-point navigation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-3-visuomotor-policy-for-a-humanoid-robot">Demo 3: Visuomotor Policy for a Humanoid Robot</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#download-the-dataset">Download the Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Train a policy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-results-demo-2">Visualize the results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#common-pitfalls-when-generating-data">Common Pitfalls when Generating Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-your-own-isaac-lab-mimic-compatible-environments">Creating Your Own Isaac Lab Mimic Compatible Environments</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-it-works">How it works</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration-and-subtask-definition">Configuration and subtask definition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#subtask-annotation">Subtask annotation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#helpers-for-demonstration-generation">Helpers for demonstration generation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#registering-the-environment">Registering the environment</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tips-for-successful-data-generation-with-isaac-lab-mimic">Tips for Successful Data Generation with Isaac Lab Mimic</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#splitting-subtasks">Splitting subtasks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#selecting-number-of-interpolation-steps">Selecting number of interpolation steps</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Isaac Lab Project Developers.
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022-2025, The Isaac Lab Project Developers..
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on Oct 15, 2025.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>